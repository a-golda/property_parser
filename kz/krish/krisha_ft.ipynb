{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b8940d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-07T23:25:23.021261Z",
     "start_time": "2023-10-07T23:25:22.806343Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803899a0",
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2023-10-07T23:24:51.278578Z",
     "start_time": "2023-10-07T23:24:51.272709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "class ScraperKrisha:\n",
    "    \"\"\"\n",
    "    Gett all links and all content from https://krisha.kz/arenda/kvartiry/\n",
    "    We can improve it. not use bs4 but regex and execute it in parallel.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.cities = ['almaty', 'astana', 'shymkent']\n",
    "        \n",
    "    def scrap(self):\n",
    "        links = {} \n",
    "        for city in self.cities:\n",
    "            print(city)\n",
    "            city_links = []\n",
    "            page = 1\n",
    "            while True:\n",
    "                print(page)\n",
    "                url = self.get_one_link(city, page)\n",
    "                tmp_links = self.get_links_from_page(url)\n",
    "                if len(tmp_links) == 0:\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "                for link in tmp_links:\n",
    "                    city_links.append(link)\n",
    "                page+=1\n",
    "            links[city] = city_links\n",
    "        return links\n",
    "                \n",
    "                \n",
    "    def get_one_link(self, city, page):\n",
    "        url = f'https://krisha.kz/arenda/kvartiry/{city}/?rent-period-switch=%2Farenda%2Fkvartiry&page={page}'\n",
    "        return url\n",
    "    \n",
    "    def get_links_from_page(self, page_link):\n",
    "        res_links = []\n",
    "        res = requests.get(page_link)\n",
    "        soup = BeautifulSoup(res.content)\n",
    "        global cards\n",
    "        cards = soup.find_all('a', 'a-card__title')\n",
    "        for card in cards:\n",
    "            href = card.attrs.get('href')\n",
    "            res_links.append(href)\n",
    "        return res_links\n",
    "    \n",
    "    def get_data_from_link(self, page_link):\n",
    "        r = requests.get(f\"https://krisha.kz{page_link}\")\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        \n",
    "        title = soup.find('h1').text\n",
    "        price = soup.find('div', 'offer__price').text\n",
    "        city_area = soup.find('div', 'offer__location offer__advert-short-info').text\n",
    "        residential_complex = soup.find('div', {'data-name':'map.complex'}).find('div', 'offer__advert-short-info').text\n",
    "        area_sq_m = soup.find('div', {'data-name':'live.square'}).find('div', 'offer__advert-short-info').text\n",
    "        renovation = [soup.find('div', {'data-name':'flat.rent_renovation'}).find('div', 'offer__advert-short-info').text,\n",
    "                     soup.find('dt', {'data-name':'flat.rent_renovation'}).text]\n",
    "        security = [soup.find('div', {'data-name':'flat.security'}).find('div', 'offer__advert-short-info').text,\n",
    "                   soup.find('dt', {'data-name':'flat.security'}).text]\n",
    "        priv_dorm = [soup.find('div', {'data-name':'flat.priv_dorm'}).find('div', 'offer__advert-short-info').text,\n",
    "            soup.find('dt', {'data-name':'flat.priv_dorm'}).text]\n",
    "        furniture = [soup.find('div', {'data-name':'flat.furniture'}).find('div', 'offer__advert-short-info').text,\n",
    "            soup.find('dt', {'data-name':'flat.furniture'}).text]\n",
    "        live_furniture = [soup.find('div', {'data-name':'live.furniture'}).find('div', 'offer__advert-short-info').text,\n",
    "                          soup.find('dt', {'data-name':'live.furniture'}).text]\n",
    "        kitchen_studio_flag = [soup.find('div', {'data-name':'kitchen_studio'}).find('div', 'offer__advert-short-info').text,\n",
    "                              soup.find('dt', {'data-name':'kitchen_studio'}).text]\n",
    "        floor = [soup.find('div', {'data-name':'flat.floor'}).find('div', 'offer__advert-short-info').text,\n",
    "                soup.find('dt', {'data-name':'flat.floor'}).text]\n",
    "        building = [soup.find('div', {'data-name':'flat.building'}).find('div', 'offer__advert-short-info').text,\n",
    "                   soup.find('dt', {'data-name':'flat.building'}).text]\n",
    "        house_year = [soup.find('div', {'data-name':'house.year'}).find('div', 'offer__advert-short-info').text,\n",
    "                     soup.find('dt', {'data-name':'house.year'}).text]\n",
    "        inet_type = [soup.find('div', {'data-name':'inet.type'}).find('div', 'offer__advert-short-info').text,\n",
    "                    soup.find('dt', {'data-name':'inet.type'}).text]\n",
    "        flat_toilet = [soup.find('div', {'data-name':'flat.toilet'}).find('div', 'offer__advert-short-info').text,\n",
    "                       soup.find('dt', {'data-name':'flat.toilet'}).text]\n",
    "        flat_balcony = [soup.find('div', {'data-name':'flat.balcony'}).find('div', 'offer__advert-short-info').text,\n",
    "                       soup.find('dt', {'data-name':'flat.balcony'}).text]\n",
    "        flat_balcony_g = [soup.find('div', {'data-name':'flat.balcony_g'}).find('div', 'offer__advert-short-info').text,\n",
    "                          soup.find('dt', {'data-name':'flat.balcony_g'}).text]\n",
    "        flat.door = [soup.find('div', {'data-name':'flat.door'}).find('div', 'offer__advert-short-info').text,\n",
    "                     soup.find('dt', {'data-name':'flat.door'}).text]\n",
    "        flat.parking = [soup.find('div', {'data-name':'flat.parking'}).find('div', 'offer__advert-short-info').text,\n",
    "                        soup.find('dt', {'data-name':'flat.parking'}).text]\n",
    "        flat.flooring = [soup.find('div', {'data-name':'flat.flooring'}).find('div', 'offer__advert-short-info').text,\n",
    "                         soup.find('dt', {'data-name':'flat.flooring'}).text]\n",
    "        flat_facilities = [soup.find('div', {'data-name':'flat.balcony'}).find('div', 'offer__advert-short-info').text, \n",
    "                          soup.find('dt', {'data-name':'flat.furniture'}).text]\n",
    "        who_match = [soup.find('div', {'data-name':'who_match'}).find('div', 'offer__advert-short-info').text,\n",
    "                    soup.find('dt', {'data-name':'who_match'}).text]\n",
    "        separated_toilet = [soup.find('div', {'data-name':'separated_toilet'}).find('div', 'offer__advert-short-info').text,\n",
    "                           soup.find('dt', {'data-name':'separated_toilet'}).text]\n",
    "        toilet_count = [soup.find('div', {'data-name':'toilet_count'}).find('div', 'offer__advert-short-info').text,\n",
    "                       soup.find('dt', {'data-name':'toilet_count'}).text]\n",
    "        bathroom = [soup.find('div', {'data-name':'bathroom'}).find('div', 'offer__advert-short-info').text,\n",
    "                   soup.find('dt', {'data-name':'bathroom'}).text]\n",
    "        window_side = [soup.find('div', {'data-name':'window_side'}).find('div', 'offer__advert-short-info').text,\n",
    "                       soup.find('dt', {'data-name':'window_side'}).text]\n",
    "        balcony_count = [soup.find('div', {'data-name':'balcony_count'}).find('div', 'offer__advert-short-info').text,\n",
    "                         soup.find('dt', {'data-name':'balcony_count'}).text]\n",
    "        loggia_count = [soup.find('div', {'data-name':'loggia_count'}).find('div', 'offer__advert-short-info').text,\n",
    "                        soup.find('dt', {'data-name':'loggia_count'}).text]\n",
    "        ceiling = [soup.find('div', {'data-name':'ceiling'}).find('div', 'offer__advert-short-info').text,\n",
    "                  soup.find('dt', {'data-name':'ceiling'}).text]\n",
    "        photos = [picture.attrs.get('src') for picture in soup.find_all('img')]\n",
    "        owners_name = soup.find('div', 'owners__name').text\n",
    "        owner_type = soup.find('div', 'owners__label owners__label--transparent label-user-identified-company').text\n",
    "        description = soup.find('div', 'a-text a-text-white-spaces').text\n",
    "        since = soup.find('div', 'offer__views').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45fecdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = ScraperKrisha()\n",
    "general_links = scraper.scrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c790b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f\"https://krisha.kz{general_links['almaty'][12]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9711625",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "45c4f9b2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9966c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1551dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = []\n",
    "for l in tqdm.tqdm(links_general_links['almaty'][:200]):\n",
    "    r = requests.get(f\"https://krisha.kz{l}\")\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    tmp = [i.find('dt').attrs.get('data-name') for i in soup.find_all('dl')]\n",
    "    for j in tmp:\n",
    "        if j not in ny:\n",
    "            ny.append(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
